{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12cd450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('/data/scratch/rdeng/enhancer_project/ipython_notebooks/')\n",
    "from helper import IOHelper, SequenceHelper \n",
    "from deeplift.visualization import viz_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e3613",
   "metadata": {},
   "source": [
    "#### Prepare files for TF-modisco-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3554889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold\n",
    "\n",
    "# category5 -> category_5\n",
    "NSC_max = 7.73604582550066 # minimum: 1.40219933979478, maximum: 7.73604582550066\n",
    "ESC_max = 5.70545787726145 # minimum: 1.48829212312168, maximum: 5.70545787726145\n",
    "\n",
    "NSC_category5 = 1.40219933979478 # minimum: 1.40219933979478, maximum: 7.73604582550066\n",
    "ESC_category5 = 1.48829212312168 # minimum: 1.48829212312168, maximum: 5.70545787726145\n",
    "\n",
    "# category4 -> category_4\n",
    "NSC_category4 = 1.14848354443742 # minimum: 1.14848354443742, maximum: 1.40219325414005\n",
    "ESC_category4 = 1.15041322844751 # minimum: 1.15041322844751, maximum: 1.48825248552868\n",
    "\n",
    "# category3 -> category_3\n",
    "NSC_category3 = 0.972399595786853 # minimum: 0.972399595786853, maximum: 1.14847961165673\n",
    "ESC_category3 = 0.934903719163151 # minimum: 0.934903719163151, maximum: 1.15039662982546\n",
    "\n",
    "# category2 -> category_2\n",
    "NSC_category2 = 0.791864633976558 # minimum: 0.791864633976558, maximum: 0.972393932644748\n",
    "ESC_category2 = 0.740407828029512 # minimum: 0.740407828029512, maximum: 0.9348999542536\n",
    "\n",
    "# category1 -> category_1\n",
    "NSC_category1 = 0 # minimum: 0, maximum: 0.791863939840448\n",
    "ESC_category1 = 0 # minimum: 0, maximum: 0.740404902305098  \n",
    "\n",
    "# load the contribution scores\n",
    "contri_NSC = np.load('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/Whole/shap_explanations_NSC.npy')\n",
    "contri_ESC = np.load('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/Whole/shap_explanations_ESC.npy')\n",
    "# acutually inp_NSC and inp_ESC are same\n",
    "inp_NSC = np.load('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/Whole/inp_NSC.npy')\n",
    "inp_ESC = np.load('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/Whole/inp_ESC.npy')\n",
    "\n",
    "# load initial dataset to filter for NSC-high, ESC-high and common-high\n",
    "file_seq = str(\"/data/scratch/rdeng/enhancer_project/data/Enhancer.fa\")\n",
    "input_fasta = IOHelper.get_fastas_from_file(file_seq, uppercase=True)  \n",
    "\n",
    "Activity = pd.read_table(\"/data/scratch/rdeng/enhancer_project/data/Enhancer_activity.txt\")\n",
    "\n",
    "NSC_category5_idx = np.where(np.logical_and(Activity.NSC_log2_enrichment >= NSC_category5, Activity.NSC_log2_enrichment <= NSC_max))[0]\n",
    "ESC_category5_idx = np.where(np.logical_and(Activity.ESC_log2_enrichment >= ESC_category5, Activity.ESC_log2_enrichment <= ESC_max))[0]\n",
    "\n",
    "# select contribution scores\n",
    "contri_NSC_category5 = contri_NSC[NSC_category5_idx]\n",
    "contri_ESC_category5 = contri_ESC[ESC_category5_idx]\n",
    "\n",
    "inp_NSC_category5 = inp_NSC[NSC_category5_idx]\n",
    "inp_ESC_category5 = inp_ESC[ESC_category5_idx]\n",
    "\n",
    "\n",
    "# save \n",
    "# np.save('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/5_categories/Category_5/shap_explanations_NSC_category5.npy', contri_NSC_category5)\n",
    "# np.save('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/5_categories/Category_5/shap_explanations_ESC_category5.npy', contri_ESC_category5)\n",
    "\n",
    "# np.save('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/5_categories/Category_5/inp_NSC_category5.npy', inp_NSC_category5)\n",
    "# np.save('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/5_categories/Category_5/inp_ESC_category5.npy', inp_ESC_category5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5cbbdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the motif setting is 5000 \n",
    "!mkdir -p /data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/5_categories/Category_5/h5Totable/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d88a21",
   "metadata": {},
   "source": [
    "#### Make tables that contains enhancer ID, motif, motif_start and motif_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a84cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 different results: NSC_high, common_Nhigh, NSC_high_ESCmodel, ESC_high, common_Ehigh, ESC_high_NSCmodel\n",
    "# we need to concatenate: enhancer_Id|patterns|motifs|motif_start|motif_end\n",
    "# motif_start is shifted 250 bp\n",
    "\n",
    "def motif_H5ToTable(h5, fasta_group):\n",
    "    \"\"\"\n",
    "    h5: motifs h5 file\n",
    "    fasta_group: dataframe with the enhancer ID\n",
    "    concatenate motifs in h5 with input_fasta with enhancer id \n",
    "    \"\"\"\n",
    "    # retrive the information from the h5 and shape it into table\n",
    "    data = []\n",
    "    for pattern_type in ['pos_patterns', 'neg_patterns']:\n",
    "        if pattern_type not in h5: # some h5 only has neg_patterns\n",
    "            continue\n",
    "        patterns = h5[pattern_type]\n",
    "        pattern_names = list(patterns.keys())\n",
    "        for pattern_name in pattern_names:\n",
    "            seqlets = patterns[pattern_name]['seqlets']\n",
    "            example_idx = seqlets['example_idx'][()] # extract example_idx information\n",
    "            start = seqlets['start'][()]  # extract start information\n",
    "            end = seqlets['end'][()]  # extract end information\n",
    "            for idx, s, e in zip(example_idx, start, end):\n",
    "                data.append((pattern_type, pattern_name, idx, s, e))  # append start and end to the data list\n",
    "    df = pd.DataFrame(data, columns=['pattern_type', 'pattern_name', 'example_idx', 'motif_start', 'motif_end'])\n",
    "    # the start and end shifted 250bp\n",
    "    df['motif_start'] = df['motif_start'] + 250\n",
    "    df['motif_end'] = df['motif_end'] + 250\n",
    "    # join with enhancer ID\n",
    "    merge_df = pd.merge(fasta_group, df, right_on='example_idx', left_index=True, how='left')\n",
    "    merge_df.drop(['sequence', 'example_idx'], axis=1, inplace=True)\n",
    "    \n",
    "    return merge_df\n",
    "\n",
    "def motif_location(table):\n",
    "    \"\"\"\n",
    "    table: the output of motif_H5ToTable\n",
    "    add a new column: motif location\n",
    "    \"\"\"\n",
    "    new_table = table.copy()  # Make a copy of the input table to avoid modifying it directly\n",
    "    new_coordinates = []\n",
    "    for coordinate, motif_start in zip(new_table['location'], new_table['motif_start']):\n",
    "        chromosome, interval = coordinate.split(':')\n",
    "        start, end = interval.split('-')\n",
    "        \n",
    "        midpoint = (int(start) + int(end)) // 2\n",
    "        new_start = midpoint - 500 + motif_start  # Move the start position left by 500 base pairs, add the value of \"extension_start\", but not past the beginning of the chromosome\n",
    "        new_end = new_start + 30  # Move the end position right by 500 base pairs and add the value of \"extension_start\"\n",
    "        \n",
    "\n",
    "        if math.isnan(new_start):\n",
    "            new_coordinate = float('nan')\n",
    "        else:\n",
    "            new_coordinate = f\"{chromosome}:{int(new_start)}-{int(new_end)}\"\n",
    "        new_coordinates.append(new_coordinate)\n",
    "    new_table['motif_location'] = new_coordinates\n",
    "    new_table.drop(['motif_start', 'motif_end'], axis=1, inplace=True)\n",
    "    \n",
    "    return new_table\n",
    "\n",
    "dic = {'NSC_category5': NSC_category5_idx, \n",
    "       'ESC_category5': ESC_category5_idx}\n",
    "\n",
    "writer = pd.ExcelWriter(\"/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/5_categories/Category_5/h5Totable/enhancer_motif.xlsx\") # Arbitrary output name\n",
    "for group_name, idx_name in dic.items():\n",
    "    fasta_group = input_fasta[input_fasta.index.isin(idx_name)].reset_index(drop=True)\n",
    "    filename = str(\"/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/5_categories/Category_5/\" + group_name + \"/out_\" + group_name + \".h5\")\n",
    "    h5 = h5py.File(filename, \"r\")\n",
    "\n",
    "    h5_table = motif_H5ToTable(h5, fasta_group)\n",
    "    motif_table = motif_location(h5_table)\n",
    "    \n",
    "\n",
    "    motif_table.to_excel(writer, sheet_name=os.path.splitext(group_name)[0], index=False)\n",
    "writer.save()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_H5ToTable(h5, fasta_group):\n",
    "    \"\"\"\n",
    "    h5: motifs h5 file\n",
    "    fasta_group: dataframe with the enhancer ID\n",
    "    concatenate motifs in h5 with input_fasta with enhancer id \n",
    "    \"\"\"\n",
    "    # retrive the information from the h5 and shape it into table\n",
    "    data = []\n",
    "    for pattern_type in ['pos_patterns', 'neg_patterns']:\n",
    "        if pattern_type not in h5: # some h5 only has neg_patterns\n",
    "            continue\n",
    "        patterns = h5[pattern_type]\n",
    "        pattern_names = list(patterns.keys())\n",
    "        for pattern_name in pattern_names:\n",
    "            seqlets = patterns[pattern_name]['seqlets']\n",
    "            example_idx = seqlets['example_idx'][()] # extract example_idx information\n",
    "            start = seqlets['start'][()]  # extract start information\n",
    "            end = seqlets['end'][()]  # extract end information\n",
    "            for idx, s, e in zip(example_idx, start, end):\n",
    "                data.append((pattern_type, pattern_name, idx, s, e))  # append start and end to the data list\n",
    "    df = pd.DataFrame(data, columns=['pattern_type', 'pattern_name', 'example_idx', 'motif_start', 'motif_end'])\n",
    "    \n",
    "    # the start and end shifted 250bp\n",
    "    df['motif_start'] = df['motif_start'] + 250\n",
    "    df['motif_end'] = df['motif_end'] + 250\n",
    "    # join with enhancer ID\n",
    "    merge_df = pd.merge(fasta_group, df, right_on='example_idx', left_index=True, how='left')\n",
    "    merge_df.drop(['sequence', 'example_idx'], axis=1, inplace=True)\n",
    "    \n",
    "    return merge_df\n",
    "\n",
    "\n",
    "fasta_group = input_fasta[input_fasta.index.isin(NSC_high_idx)].reset_index(drop=True)\n",
    "filename = str(\"/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/5_categories/Category_5/5000/NSC_high/out_NSC_high.h5\")\n",
    "h5 = h5py.File(filename, \"r\")\n",
    "\n",
    "motif_table = motif_H5ToTable(h5, fasta_group)\n",
    "\n",
    "def motif_location(table):\n",
    "    \"\"\"\n",
    "    table: the output of motif_H5ToTable\n",
    "    add motif location\n",
    "    \"\"\"\n",
    "    new_table = table.copy()  # Make a copy of the input table to avoid modifying it directly\n",
    "    \n",
    "    # some enhancers are padded with 0, then need to adjust the coordinates\n",
    "    new_coordinates = []\n",
    "    for coordinate, motif_start in zip(new_table['location'], new_table['motif_start']):\n",
    "        chromosome, interval = coordinate.split(':')\n",
    "        start, end = interval.split('-')\n",
    "        \n",
    "        midpoint = (int(start) + int(end)) // 2\n",
    "        new_start = midpoint - 500 + motif_start  # Move the start position left by 500 base pairs, add the value of \"extension_start\", but not past the beginning of the chromosome\n",
    "        new_end = new_start + 30  # Move the end position right by 500 base pairs and add the value of \"extension_start\"\n",
    "        \n",
    "        # some enhancers don't have motifs and are marked with nan\n",
    "        if math.isnan(new_start):\n",
    "            new_coordinate = float('nan')\n",
    "        else:\n",
    "            new_coordinate = f\"{chromosome}:{int(new_start)}-{int(new_end)}\"\n",
    "        new_coordinates.append(new_coordinate)\n",
    "    new_table['motif_location'] = new_coordinates\n",
    "    new_table.drop(['motif_start', 'motif_end'], axis=1, inplace=True)\n",
    "    \n",
    "    return new_table\n",
    "\n",
    "motif_location(motif_table)\n",
    "\n",
    "\n",
    "tomtom_result = pd.read_table(\"/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/NSC_ESC_common/5000/common_Ehigh/tomtom_results.txt\", header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f518caa",
   "metadata": {},
   "source": [
    "#### Visualize motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49048e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold\n",
    "NSC_top10 = 1.65208463524962\n",
    "ESC_top10 = 1.82043324245546\n",
    "\n",
    "# load contribution score from Test data\n",
    "contri_scores = np.load('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/NSC_ESC_common/shap_explanations_ESC_high.npy')\n",
    "inps = np.load('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/NSC_ESC_common/inp_ESC_high.npy')\n",
    "\n",
    "# load initial dataset to filter for NSC-high, ESC-high and common-high\n",
    "file_seq = str(\"/data/scratch/rdeng/enhancer_project/data/Enhancer.fa\")\n",
    "input_fasta = IOHelper.get_fastas_from_file(file_seq, uppercase=True)  \n",
    "\n",
    "Activity = pd.read_table(\"/data/scratch/rdeng/enhancer_project/data/Enhancer_activity.txt\")\n",
    "\n",
    "NSC_high_idx = np.where(np.logical_and(Activity.NSC_log2_enrichment >= NSC_top10, Activity.ESC_log2_enrichment < ESC_top10))[0]\n",
    "ESC_high_idx = np.where(np.logical_and(Activity.NSC_log2_enrichment < NSC_top10, Activity.ESC_log2_enrichment >= ESC_top10))[0]\n",
    "common_high_idx = np.where(np.logical_and(Activity.NSC_log2_enrichment >= NSC_top10, Activity.ESC_log2_enrichment >= ESC_top10))[0]\n",
    "\n",
    "NSC_high = input_fasta[input_fasta.index.isin(NSC_high_idx)].reset_index(drop=True)\n",
    "ESC_high = input_fasta[input_fasta.index.isin(ESC_high_idx)].reset_index(drop=True)\n",
    "common_high = input_fasta[input_fasta.index.isin(common_high_idx)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSC-high\n",
    "NSC_high.loc[NSC_high['location'] == 'chr8:123479279-123480279']\n",
    "NSC_high.iloc[[3978]]\n",
    "# test = NSC_high[NSC_high.index.isin(motif_idx1)]\n",
    "# test.loc[test['location'] == 'chr8:123479279-123480279']\n",
    "\n",
    "# ESC-high\n",
    "ESC_high.loc[ESC_high['location'] == 'chr2:121490069-121490672']\n",
    "ESC_high.iloc[[3451]]\n",
    "# test = ESC_high[ESC_high.index.isin(motif_idx1)]\n",
    "# test.loc[test['location'] == 'chr2:121490069-121490672']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from deeplift.visualization import viz_sequence\n",
    "\n",
    "filename = \"/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/NSC_ESC_common/5000/NSC_high/out_NSC_high.h5\"\n",
    "f = h5py.File(filename, \"r\")\n",
    "\n",
    "# in total three layers of the h5\n",
    "print(list(f['neg_patterns']))\n",
    "print(list(f['neg_patterns']['pattern_0']))\n",
    "print(list(f['neg_patterns']['pattern_0']['seqlets']))\n",
    "# np.intersect1d(motif_idx1, motif_idx2)\n",
    "\n",
    "motif_idx1 = f['neg_patterns']['pattern_0']['seqlets']['example_idx'][()]\n",
    "motif_start1 = f['neg_patterns']['pattern_0']['seqlets']['start'][()]\n",
    "motif_end1 = f['neg_patterns']['pattern_0']['seqlets']['end'][()]\n",
    "print(motif_idx1)\n",
    "print(motif_start1)\n",
    "print(motif_end1)\n",
    "\n",
    "# np.where(motif_idx1 == 3451)[0][0]\n",
    "# motif_start1[np.where(motif_idx1 == 3451)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05de01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7375 is the previous one that I plotted with TP53 and YY2 for NSC-high\n",
    "mod_viz = np.multiply(contri_scores[7375], inps[7375])\n",
    "viz_sequence.plot_weights(mod_viz[:,:], subticks_frequency=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3079 TP53 for ESC-high\n",
    "# mod_viz = np.multiply(contri_scores[3079], inps[3079])\n",
    "# viz_sequence.plot_weights(mod_viz[:,440:480], subticks_frequency=20)\n",
    "\n",
    "# 3451: the previous selected regions\n",
    "\n",
    "# all plus 250\n",
    "# pos_1 -> 45\n",
    "# neg_2 -> 273, neg_7 -> 357, neg_12 -> 226\n",
    "\n",
    "\n",
    "mod_viz = np.multiply(contri_scores[3451], inps[3451])\n",
    "viz_sequence.plot_weights(mod_viz[:,:], subticks_frequency=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36562fd",
   "metadata": {},
   "source": [
    "#### Check the motifs sites of selected HPO related NSC-high enhancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_enhancer = pd.read_csv(\"/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/NSC_ESC_common/NSC_high_selectedCoordinates.csv\")\n",
    "\n",
    "file_seq = str(\"/data/scratch/rdeng/enhancer_project/data/Enhancer.fa\")\n",
    "input_fasta = IOHelper.get_fastas_from_file(file_seq, uppercase=True)  \n",
    "\n",
    "# load the contribution scores\n",
    "contri_NSC = np.load('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/Whole/shap_explanations_NSC.npy')\n",
    "inp_NSC = np.load('/data/scratch/rdeng/enhancer_project/ipython_notebooks/2D/contri_score/Whole/inp_NSC.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533251d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_fasta = input_fasta[input_fasta[\"location\"].isin(select_enhancer[\"location\"])]\n",
    "\n",
    "select_idx = input_fasta[input_fasta[\"location\"].isin(select_enhancer[\"location\"])].index.tolist()\n",
    "select_contri = contri_NSC[select_idx]\n",
    "select_inp = inp_NSC[select_idx]\n",
    "\n",
    "mod_viz = np.multiply(select_contri, select_inp)\n",
    "\n",
    "for i in range(mod_viz.shape[0]):\n",
    "    print(select_fasta.iloc[i,0])\n",
    "    viz_sequence.plot_weights(mod_viz[i,:,:], subticks_frequency=20)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
